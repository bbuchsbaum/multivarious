% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cPCA.R
\name{cPCA}
\alias{cPCA}
\title{Contrastive PCA (cPCA) with Adaptive Computation Methods}
\usage{
cPCA(
  X_f,
  X_b,
  ncomp = min(dim(X_f)[2]),
  preproc = center(),
  lambda = 0,
  method = c("geigen", "primme", "sdiag", "corpcor"),
  allow_transpose = TRUE,
  ...
)
}
\arguments{
\item{X_f}{A numeric matrix representing the foreground dataset, with dimensions (samples x features).}

\item{X_b}{A numeric matrix representing the background dataset, with dimensions (samples x features).}

\item{ncomp}{Number of components to estimate. Defaults to \code{min(ncol(X_f))}.}

\item{preproc}{A pre-processing function (default: \code{center()}), applied to both \code{X_f} and \code{X_b} before analysis.}

\item{lambda}{Shrinkage parameter for covariance estimation. Defaults to 0. Used by \code{corpcor::cov.shrink} or \code{crossprod.powcor.shrink}.}

\item{method}{A character string specifying the computation method. One of:
\describe{
\item{"geigen"}{Use \code{geneig} for the generalized eigenvalue problem (default).}
\item{"primme"}{Use \code{geneig} with the PRIMME library for potentially more efficient solvers.}
\item{"sdiag"}{Use a spectral decomposition method for symmetric matrices in \code{geneig}.}
\item{"corpcor"}{Use a corpcor-based whitening approach followed by PCA.}
}}

\item{...}{Additional arguments passed to underlying functions such as \code{geneig} or covariance estimation.}
}
\value{
A \code{bi_projector} object containing:
\describe{
\item{v}{A (features x ncomp) matrix of eigenvectors (loadings).}
\item{s}{A (samples x ncomp) matrix of scores, i.e., projections of \code{X_f} onto the eigenvectors.}
\item{sdev}{A vector of length \code{ncomp} giving the square-root of the eigenvalues.}
\item{preproc}{The pre-processing object used.}
}
}
\description{
Contrastive PCA (cPCA) finds directions that capture the variation in a "foreground" dataset \eqn{X_f} that is not present (or less present) in a "background" dataset \eqn{X_b}. This function adaptively chooses how to solve the generalized eigenvalue problem based on the dataset sizes and the chosen method:
}
\details{
\enumerate{
\item \strong{method = "corpcor"}: Uses a corpcor-based whitening approach (\code{crossprod.powcor.shrink}) to transform the data, then performs a standard PCA on the transformed foreground data.
\item \strong{method \in \{"geigen","primme","sdiag"\} and moderate number of features (D):} Directly forms covariance matrices and uses \code{geneig} to solve the generalized eigenvalue problem.
\item \strong{method \in \{"geigen","primme","sdiag"\} and large number of features (D >> N):} Uses an SVD-based reduction on the background data to avoid forming large \eqn{D \times D} matrices. This reduces the problem to \eqn{N \times N} space.
}

\strong{Adaptive Strategy:}
\itemize{
\item If \code{method = "corpcor"}, no large covariance matrices are formed. Instead, the background data is used to "whiten" the foreground, followed by a simple PCA.
\item If \verb{method \\neq "corpcor"} and the number of features \code{D} is manageable (e.g. \code{D <= max(N_f, N_b)}), the function forms covariance matrices and directly solves the generalized eigenproblem.
\item If \verb{method \\neq "corpcor"} and \code{D} is large (e.g., tens of thousands, \code{D > max(N_f, N_b)}), it computes the SVD of the background data \code{X_b} to derive a smaller \verb{N x N} eigenproblem, thereby avoiding the costly computation of \eqn{D \times D} covariance matrices.
}

Note: If \code{lambda != 0} and \code{D} is very large, the current implementation does not fully integrate shrinkage into the large-D SVD-based approach and will issue a warning.
}
\examples{
set.seed(123)
X_f <- matrix(rnorm(2000), nrow=100, ncol=20) # Foreground: 100 samples, 20 features
X_b <- matrix(rnorm(2000), nrow=100, ncol=20) # Background: same size
# Default method (geigen), small dimension scenario
res <- cPCA(X_f, X_b, ncomp=5)
plot(res$s[,1], res$s[,2], main="cPCA scores (component 1 vs 2)")

}
